{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create adjacency matrix\n",
    "\n",
    "# Define distance metrics\n",
    "def euclidean_distance(x, y):\n",
    "    return torch.sqrt(torch.sum((x - y)**2))\n",
    "\n",
    "def inverse_distance(x, y):\n",
    "    return 1 / euclidean_distance(x, y)\n",
    "\n",
    "# Create adjacency matrix function\n",
    "def create_adjacency_matrix(data, distance_metric):\n",
    "    n = data.shape[0]\n",
    "    adjacency_matrix = torch.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:  # we don't calculate the distance of the object to itself\n",
    "                # we extract the position [x, y] for both objects i and j\n",
    "                position_i = data[i, 1:3]\n",
    "                position_j = data[j, 1:3]\n",
    "                adjacency_matrix[i, j] = distance_metric(position_i, position_j)\n",
    "    return adjacency_matrix\n",
    "\n",
    "# Validate input\n",
    "def validate_input(X, adjacency_matrix):\n",
    "    # X should be a 2D tensor\n",
    "    assert X.dim() == 2, f\"X must be 2D, but got shape {X.shape}\"\n",
    "\n",
    "    # The number of nodes should be the same in X and the adjacency matrix\n",
    "    assert X.shape[0] == adjacency_matrix.shape[0] == adjacency_matrix.shape[1], \\\n",
    "        f\"Mismatch in number of nodes: got {X.shape[0]} nodes in X, but {adjacency_matrix.shape[0]} nodes in adjacency matrix\"\n",
    "\n",
    "    # The adjacency matrix should be square\n",
    "    assert adjacency_matrix.shape[0] == adjacency_matrix.shape[1], \\\n",
    "        f\"Adjacency matrix must be square, but got shape {adjacency_matrix.shape}\"\n",
    "\n",
    "    print(\"All checks passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of initial state (model input): (8, 5)\n",
      "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
      "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
      "the shape of the input of a test data example is (8, 5)\n",
      "the shape of the target of a test data example is (8, 49, 4)\n",
      "values of the test data example at time 30:\n",
      " [[-5.85725792 -5.394571           nan         nan]\n",
      " [-6.03781257 -5.72445953         nan         nan]\n",
      " [-0.90623054 -6.93416278         nan         nan]\n",
      " [ 2.83149339 -7.50100819         nan         nan]\n",
      " [-2.85586881  1.77667501         nan         nan]\n",
      " [ 4.04424526  4.00563603         nan         nan]\n",
      " [-5.24887713 -4.83081005         nan         nan]\n",
      " [-5.81391023 -5.1109838          nan         nan]]\n",
      "note: velocity values are unobserved (NaNs) in the test data!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
    "\n",
    "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
    "If you use the velocity of the remaining trajectory for training,\n",
    "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
    "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "example = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "initial_state, remaining_trajectory = example\n",
    "print(f'shape of initial state (model input): {initial_state.shape}')\n",
    "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
    "\n",
    "body_idx = 2\n",
    "time_idx = 30\n",
    "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
    "\n",
    "test_example = load_array('data/task 2_3/test/trajectory_900.npz', task='task 3')\n",
    "test_initial_state, test_remaining_trajectory = test_example\n",
    "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
    "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
    "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
    "print('note: velocity values are unobserved (NaNs) in the test data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGELSTM(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, num_timesteps):\n",
    "        super(GraphSAGELSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(num_features, hidden_channels, batch_first=True)\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels*2)\n",
    "        self.conv2 = SAGEConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, num_classes)\n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, edge_index, batch = x.x, x.edge_index, x.batch\n",
    "\n",
    "        # 1st GraphSAGE layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # 2nd GraphSAGE layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # Reshape to (num_nodes, num_timesteps, hidden_channels)\n",
    "        x = x.view(batch.shape[0], self.num_timesteps, x.size(1))\n",
    "\n",
    "        # LSTM layer\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        # Reshape back to (num_nodes * num_timesteps, hidden_channels)\n",
    "        x = x.view(-1, x.size(2))\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, filenames, transform=None, pre_transform=None):\n",
    "        self.filenames = filenames\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filenames\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def get(self, idx):\n",
    "        X, y = load_array(self.filenames[idx], task='task 2')\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        adjacency_matrix = create_adjacency_matrix(X, inverse_distance)\n",
    "        edge_index = adjacency_matrix.nonzero().t()\n",
    "        #edge_attr = idx/10.0 #Storing the timestamp as attribute of the edge\n",
    "\n",
    "        data = Data(x=X, y=y, edge_index=edge_index)\n",
    "        #print(f\"X shape: {X.shape}, y shape: {y.shape}, edge_index shape: {edge_index.shape}\")\n",
    "        return data\n",
    "\n",
    "filenames = [f'data/task 2_3/train/trajectory_{i}.npz' for i in range(900)]\n",
    "dataset = MyDataset(root='data/task 2/train', filenames=filenames)\n",
    "\n",
    "# Prepare for validation data set\n",
    "\n",
    "val_filenames = [f'data/task 2_3/test/trajectory_{i}.npz' for i in range(901, 1000)]\n",
    "val_dataset = MyDataset(root='data/task 2/test', filenames=val_filenames)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader.dataset[0].x.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[222, 50, 16]' is invalid for input of size 3552",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)  \u001b[39m# move batch to the device\u001b[39;00m\n\u001b[0;32m     15\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# set gradients to zero\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m out \u001b[39m=\u001b[39m model(batch)  \u001b[39m# forward pass\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m criterion(out, batch\u001b[39m.\u001b[39my)  \u001b[39m# compute loss\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# backward pass (compute gradients)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[27], line 27\u001b[0m, in \u001b[0;36mGraphSAGELSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     26\u001b[0m \u001b[39m# Reshape to (num_nodes, num_timesteps, hidden_channels)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mview(batch\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_timesteps, x\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     29\u001b[0m \u001b[39m# LSTM layer\u001b[39;00m\n\u001b[0;32m     30\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[222, 50, 16]' is invalid for input of size 3552"
     ]
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"mps\" #(I've no mps support on my pc)\n",
    "hidden_channels = 16\n",
    "model = GraphSAGELSTM(num_features=5, hidden_channels=hidden_channels, num_classes=2, num_timesteps=50).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "\n",
    "for epoch in range(100):  # run for 100 epochs\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)  # move batch to the device\n",
    "        optimizer.zero_grad()  # set gradients to zero\n",
    "        out = model(batch)  # forward pass\n",
    "        loss = criterion(out, batch.y)  # compute loss\n",
    "        loss.backward()  # backward pass (compute gradients)\n",
    "        optimizer.step()  # update model parameters\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n",
    "\n",
    "    val_loss /= len(val_dataset)  # compute average validation loss\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {loss.item()}, Test Loss: {val_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([222, 49, 4])) that is different to the input size (torch.Size([222, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m         total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(predictions, batch\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m batch\u001b[39m.\u001b[39mnum_graphs\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n\u001b[1;32m---> 21\u001b[0m train_loss_static \u001b[39m=\u001b[39m compute_baseline_loss(static_baseline, dataloader)\n\u001b[0;32m     22\u001b[0m train_loss_linear \u001b[39m=\u001b[39m compute_baseline_loss(linear_baseline, dataloader)\n\u001b[0;32m     24\u001b[0m val_loss_static \u001b[39m=\u001b[39m compute_baseline_loss(static_baseline, val_dataloader)\n",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m, in \u001b[0;36mcompute_baseline_loss\u001b[1;34m(baseline_fn, dataloader)\u001b[0m\n\u001b[0;32m     15\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m     predictions \u001b[39m=\u001b[39m baseline_fn(batch\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 17\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion(predictions, batch\u001b[39m.\u001b[39;49my)\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m batch\u001b[39m.\u001b[39mnum_graphs\n\u001b[0;32m     19\u001b[0m \u001b[39mreturn\u001b[39;00m total_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader\u001b[39m.\u001b[39mdataset)\n",
      "File \u001b[1;32mc:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\nn\\functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3291\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3292\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3295\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\dagos\\miniconda3\\envs\\mlcourse\\lib\\site-packages\\torch\\functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Calculate static and linear baselines (formula on ANS)\n",
    "# THIS IS CORRECT! DO NOT CHANGE!\n",
    "\n",
    "def static_baseline(X):\n",
    "    return X[:, 1:3]  # initial x,y coordinates\n",
    "\n",
    "def linear_baseline(X):\n",
    "    return X[:, 1:3] + X[:, 3:5] * 5  # initial x,y coordinates plus velocity times time\n",
    "\n",
    "def compute_baseline_loss(baseline_fn, dataloader):\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        predictions = baseline_fn(batch.x).to(device)\n",
    "        total_loss += criterion(predictions, batch.y).item() * batch.num_graphs\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "train_loss_static = compute_baseline_loss(static_baseline, dataloader)\n",
    "train_loss_linear = compute_baseline_loss(linear_baseline, dataloader)\n",
    "\n",
    "val_loss_static = compute_baseline_loss(static_baseline, val_dataloader)\n",
    "val_loss_linear = compute_baseline_loss(linear_baseline, val_dataloader)\n",
    "\n",
    "\n",
    " # now print out with filler spaces to make it easier to read\n",
    "print(f'Training Loss   - Static Baseline: {train_loss_static:0.4f}, Linear Baseline: {train_loss_linear:0.4f}')\n",
    "print(f'Validation Loss - Static Baseline: {val_loss_static:0.4f}, Linear Baseline: {val_loss_linear:0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
