{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def load_array(filename, task):\n",
    "    datapoint = np.load(filename)\n",
    "    if task == 'task 1':\n",
    "        initial_state = datapoint['initial_state']\n",
    "        terminal_state = datapoint['terminal_state']\n",
    "        return initial_state, terminal_state\n",
    "    elif task == 'task 2' or task == 'task 3':\n",
    "        whole_trajectory = datapoint['trajectory']\n",
    "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
    "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
    "        initial_state = whole_trajectory[:, 0]\n",
    "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
    "        return initial_state, target\n",
    "    else:\n",
    "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create adjacency matrix\n",
    "\n",
    "# Define distance metrics\n",
    "def euclidean_distance(x, y):\n",
    "    return torch.sqrt(torch.sum((x - y)**2))\n",
    "\n",
    "def inverse_distance(x, y):\n",
    "    return 1 / euclidean_distance(x, y)\n",
    "\n",
    "# Create adjacency matrix function\n",
    "def create_adjacency_matrix(data, distance_metric):\n",
    "    n = data.shape[0]\n",
    "    adjacency_matrix = torch.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:  # we don't calculate the distance of the object to itself\n",
    "                # we extract the position [x, y] for both objects i and j\n",
    "                position_i = data[i, 1:3]\n",
    "                position_j = data[j, 1:3]\n",
    "                adjacency_matrix[i, j] = distance_metric(position_i, position_j)\n",
    "    return adjacency_matrix\n",
    "\n",
    "# Validate input\n",
    "def validate_input(X, adjacency_matrix):\n",
    "    # X should be a 2D tensor\n",
    "    assert X.dim() == 2, f\"X must be 2D, but got shape {X.shape}\"\n",
    "\n",
    "    # The number of nodes should be the same in X and the adjacency matrix\n",
    "    assert X.shape[0] == adjacency_matrix.shape[0] == adjacency_matrix.shape[1], \\\n",
    "        f\"Mismatch in number of nodes: got {X.shape[0]} nodes in X, but {adjacency_matrix.shape[0]} nodes in adjacency matrix\"\n",
    "\n",
    "    # The adjacency matrix should be square\n",
    "    assert adjacency_matrix.shape[0] == adjacency_matrix.shape[1], \\\n",
    "        f\"Adjacency matrix must be square, but got shape {adjacency_matrix.shape}\"\n",
    "\n",
    "    print(\"All checks passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine sample data\n",
    "\"\"\"\n",
    "This cell gives an example of loading a datapoint with numpy for task 1.\n",
    "\n",
    "The arrays returned by the function are structures as follows:\n",
    "initial_state(X): shape (n_bodies, [mass, x, y, v_x, v_y])\n",
    "terminal_state(y): shape (n_bodies, [x, y])\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X, y= load_array('data/task 1/train/trajectory_0.npz', task='task 1')\n",
    "X = torch.tensor(X, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = create_adjacency_matrix(X, inverse_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test network\n",
    "import torch\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GraphConv(num_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # 1st Graph Convolution layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # 2nd Graph Convolution layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Convert adjacency matrix to edge_index\n",
    "# WARNING! This will 'Delete' the distances between the nodes\n",
    "edge_index = adjacency_matrix.nonzero().t()\n",
    "\n",
    "# Create a Data object\n",
    "data = Data(x=X, edge_index=edge_index)\n",
    "\n",
    "# Create an instance of our GNN\n",
    "model = SimpleGNN(num_features=5, hidden_channels=32, num_classes=2)\n",
    "\n",
    "# Pass the graph through the model\n",
    "out = model(data)\n",
    "\n",
    "print(out.shape)\n",
    "edge_index[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Zoo\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels*2)\n",
    "        self.conv2 = SAGEConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # 1st GraphSAGE layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # 2nd GraphSAGE layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        # 3rd GraphSAGE layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "\n",
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, filenames, transform=None, pre_transform=None):\n",
    "        self.filenames = filenames\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filenames\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def get(self, idx):\n",
    "        X, y = load_array(self.filenames[idx], task='task 1')\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        adjacency_matrix = create_adjacency_matrix(X, inverse_distance)\n",
    "        edge_index = adjacency_matrix.nonzero().t()\n",
    "\n",
    "        data = Data(x=X, y=y, edge_index=edge_index)\n",
    "\n",
    "        return data\n",
    "\n",
    "filenames = [f'data/task 1/train/trajectory_{i}.npz' for i in range(900)]\n",
    "dataset = MyDataset(root='data/task 1/train', filenames=filenames)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# Prepare for validation data set\n",
    "\n",
    "val_filenames = [f'data/task 1/test/trajectory_{i}.npz' for i in range(901, 1000)]\n",
    "val_dataset = MyDataset(root='data/task 1/test', filenames=val_filenames)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 18.775009155273438, Test Loss: 15.298054030447295\n",
      "Epoch: 2, Training Loss: 13.72278118133545, Test Loss: 10.26056290636159\n",
      "Epoch: 3, Training Loss: 8.659708023071289, Test Loss: 5.869230491946442\n",
      "Epoch: 4, Training Loss: 7.579400062561035, Test Loss: 5.277372755185522\n",
      "Epoch: 5, Training Loss: 7.039554119110107, Test Loss: 5.104083800556684\n",
      "Epoch: 6, Training Loss: 6.58915376663208, Test Loss: 4.958018618400651\n",
      "Epoch: 7, Training Loss: 6.33601713180542, Test Loss: 4.8431312074564925\n",
      "Epoch: 8, Training Loss: 6.14321756362915, Test Loss: 4.749769208407161\n",
      "Epoch: 9, Training Loss: 5.98360013961792, Test Loss: 4.673894207886975\n",
      "Epoch: 10, Training Loss: 5.84599494934082, Test Loss: 4.615942061549485\n",
      "Epoch: 11, Training Loss: 5.74440860748291, Test Loss: 4.570442262322012\n",
      "Epoch: 12, Training Loss: 5.638522148132324, Test Loss: 4.533588257702914\n",
      "Epoch: 13, Training Loss: 5.541761875152588, Test Loss: 4.498996423952507\n",
      "Epoch: 14, Training Loss: 5.445616245269775, Test Loss: 4.469813219224564\n",
      "Epoch: 15, Training Loss: 5.360722064971924, Test Loss: 4.44538355355311\n",
      "Epoch: 16, Training Loss: 5.275803565979004, Test Loss: 4.421086499185273\n",
      "Epoch: 17, Training Loss: 5.194608211517334, Test Loss: 4.399503329787591\n",
      "Epoch: 18, Training Loss: 5.105077266693115, Test Loss: 4.377108537789547\n",
      "Epoch: 19, Training Loss: 5.0319366455078125, Test Loss: 4.360313480550593\n",
      "Epoch: 20, Training Loss: 4.959531784057617, Test Loss: 4.343052363154864\n",
      "Epoch: 21, Training Loss: 4.8815155029296875, Test Loss: 4.327162003276324\n",
      "Epoch: 22, Training Loss: 4.814940929412842, Test Loss: 4.30731344945503\n",
      "Epoch: 23, Training Loss: 4.742807388305664, Test Loss: 4.290827804141575\n",
      "Epoch: 24, Training Loss: 4.665524959564209, Test Loss: 4.276835564411048\n",
      "Epoch: 25, Training Loss: 4.592926979064941, Test Loss: 4.263858335186737\n",
      "Epoch: 26, Training Loss: 4.529709815979004, Test Loss: 4.2491299792973685\n",
      "Epoch: 27, Training Loss: 4.4549360275268555, Test Loss: 4.239332700016523\n",
      "Epoch: 28, Training Loss: 4.408207416534424, Test Loss: 4.218976764967947\n",
      "Epoch: 29, Training Loss: 4.3503522872924805, Test Loss: 4.206754433988321\n",
      "Epoch: 30, Training Loss: 4.300017833709717, Test Loss: 4.189709766946658\n",
      "Epoch: 31, Training Loss: 4.257002830505371, Test Loss: 4.176645206682609\n",
      "Epoch: 32, Training Loss: 4.201469898223877, Test Loss: 4.159205740148371\n",
      "Epoch: 33, Training Loss: 4.147042274475098, Test Loss: 4.14959024660515\n",
      "Epoch: 34, Training Loss: 4.102409839630127, Test Loss: 4.133773112537885\n",
      "Epoch: 35, Training Loss: 4.050755977630615, Test Loss: 4.12525136061389\n",
      "Epoch: 36, Training Loss: 4.008694171905518, Test Loss: 4.109644923547302\n",
      "Epoch: 37, Training Loss: 3.966848611831665, Test Loss: 4.095432112915347\n",
      "Epoch: 38, Training Loss: 3.912707567214966, Test Loss: 4.085536571464154\n",
      "Epoch: 39, Training Loss: 3.8634021282196045, Test Loss: 4.06286867459615\n",
      "Epoch: 40, Training Loss: 3.8160018920898438, Test Loss: 4.054261335218795\n",
      "Epoch: 41, Training Loss: 3.770578145980835, Test Loss: 4.026621069570984\n",
      "Epoch: 42, Training Loss: 3.677191734313965, Test Loss: 4.015439262293806\n",
      "Epoch: 43, Training Loss: 3.6467180252075195, Test Loss: 3.994724312213936\n",
      "Epoch: 44, Training Loss: 3.5650393962860107, Test Loss: 3.9871202261760983\n",
      "Epoch: 45, Training Loss: 3.5237181186676025, Test Loss: 3.966755659893306\n",
      "Epoch: 46, Training Loss: 3.478221893310547, Test Loss: 3.9555267950501105\n",
      "Epoch: 47, Training Loss: 3.4531943798065186, Test Loss: 3.936377368792139\n",
      "Epoch: 48, Training Loss: 3.4071850776672363, Test Loss: 3.9268015033066876\n",
      "Epoch: 49, Training Loss: 3.382580280303955, Test Loss: 3.9124981779040713\n",
      "Epoch: 50, Training Loss: 3.3373215198516846, Test Loss: 3.9020911732105295\n",
      "Epoch: 51, Training Loss: 3.338127613067627, Test Loss: 3.8828298539826362\n",
      "Epoch: 52, Training Loss: 3.2958245277404785, Test Loss: 3.8760224062987048\n",
      "Epoch: 53, Training Loss: 3.2707345485687256, Test Loss: 3.862648125850793\n",
      "Epoch: 54, Training Loss: 3.24149227142334, Test Loss: 3.855281444511028\n",
      "Epoch: 55, Training Loss: 3.2159957885742188, Test Loss: 3.8462450335724183\n",
      "Epoch: 56, Training Loss: 3.19260835647583, Test Loss: 3.8376137102493133\n",
      "Epoch: 57, Training Loss: 3.170534372329712, Test Loss: 3.8280920572955197\n",
      "Epoch: 58, Training Loss: 3.12978196144104, Test Loss: 3.8262170589331426\n",
      "Epoch: 59, Training Loss: 3.1118392944335938, Test Loss: 3.8129851360513705\n",
      "Epoch: 60, Training Loss: 3.076890468597412, Test Loss: 3.807521032564568\n",
      "Epoch: 61, Training Loss: 3.04952073097229, Test Loss: 3.795284415736343\n",
      "Epoch: 62, Training Loss: 3.011387348175049, Test Loss: 3.7916535825440376\n",
      "Epoch: 63, Training Loss: 2.9644477367401123, Test Loss: 3.78670952536843\n",
      "Epoch: 64, Training Loss: 2.948453187942505, Test Loss: 3.7735944998384725\n",
      "Epoch: 65, Training Loss: 2.9108052253723145, Test Loss: 3.7693246651177454\n",
      "Epoch: 66, Training Loss: 2.8847086429595947, Test Loss: 3.7571304795717952\n",
      "Epoch: 67, Training Loss: 2.8573367595672607, Test Loss: 3.7527236806021795\n",
      "Epoch: 68, Training Loss: 2.8223934173583984, Test Loss: 3.7493716803464023\n",
      "Epoch: 69, Training Loss: 2.7955310344696045, Test Loss: 3.740018140185963\n",
      "Epoch: 70, Training Loss: 2.777209520339966, Test Loss: 3.7360759239004118\n",
      "Epoch: 71, Training Loss: 2.7584280967712402, Test Loss: 3.731520020600521\n",
      "Epoch: 72, Training Loss: 2.73539400100708, Test Loss: 3.7288366267175386\n",
      "Epoch: 73, Training Loss: 2.7138257026672363, Test Loss: 3.7259089284472995\n",
      "Epoch: 74, Training Loss: 2.699971914291382, Test Loss: 3.7193313704596624\n",
      "Epoch: 75, Training Loss: 2.692117929458618, Test Loss: 3.7176782940373276\n",
      "Epoch: 76, Training Loss: 2.6612837314605713, Test Loss: 3.7158082061343722\n",
      "Epoch: 77, Training Loss: 2.643643617630005, Test Loss: 3.7023324882141266\n",
      "Epoch: 78, Training Loss: 2.6365139484405518, Test Loss: 3.704924060840799\n",
      "Epoch: 79, Training Loss: 2.608383893966675, Test Loss: 3.700693535082268\n",
      "Epoch: 80, Training Loss: 2.6034724712371826, Test Loss: 3.6952795609079225\n",
      "Epoch: 81, Training Loss: 2.5902130603790283, Test Loss: 3.696291791068183\n",
      "Epoch: 82, Training Loss: 2.577569007873535, Test Loss: 3.6920819776226774\n",
      "Epoch: 83, Training Loss: 2.567540407180786, Test Loss: 3.685989584585633\n",
      "Epoch: 84, Training Loss: 2.553771734237671, Test Loss: 3.683795725456392\n",
      "Epoch: 85, Training Loss: 2.5506155490875244, Test Loss: 3.6822655863232083\n",
      "Epoch: 86, Training Loss: 2.5357983112335205, Test Loss: 3.678209504695854\n",
      "Epoch: 87, Training Loss: 2.5269622802734375, Test Loss: 3.677266477334379\n",
      "Epoch: 88, Training Loss: 2.512261152267456, Test Loss: 3.6770383649402194\n",
      "Epoch: 89, Training Loss: 2.5073375701904297, Test Loss: 3.6727206309636435\n",
      "Epoch: 90, Training Loss: 2.495678186416626, Test Loss: 3.6729765757165773\n",
      "Epoch: 91, Training Loss: 2.4814016819000244, Test Loss: 3.6722496627557155\n",
      "Epoch: 92, Training Loss: 2.4684720039367676, Test Loss: 3.667156206236945\n",
      "Epoch: 93, Training Loss: 2.460212469100952, Test Loss: 3.6653952080794054\n",
      "Epoch: 94, Training Loss: 2.451112747192383, Test Loss: 3.6665796366604892\n",
      "Epoch: 95, Training Loss: 2.4326415061950684, Test Loss: 3.664593118609804\n",
      "Epoch: 96, Training Loss: 2.423396587371826, Test Loss: 3.6634964401071723\n",
      "Epoch: 97, Training Loss: 2.4126858711242676, Test Loss: 3.663179772068756\n",
      "Epoch: 98, Training Loss: 2.4080395698547363, Test Loss: 3.663270303697297\n",
      "Epoch: 99, Training Loss: 2.3943288326263428, Test Loss: 3.6625659562120534\n",
      "Epoch: 100, Training Loss: 2.388228178024292, Test Loss: 3.6641255593059037\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "model = GraphSAGE(num_features=5, hidden_channels=16, num_classes=2).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "\n",
    "for epoch in range(100):  # run for 100 epochs\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)  # move batch to the device\n",
    "        optimizer.zero_grad()  # set gradients to zero\n",
    "        out = model(batch)  # forward pass\n",
    "        loss = criterion(out, batch.y)  # compute loss\n",
    "        loss.backward()  # backward pass (compute gradients)\n",
    "        optimizer.step()  # update model parameters\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            val_loss += criterion(out, batch.y).item() * batch.num_graphs\n",
    "\n",
    "    val_loss /= len(val_dataset)  # compute average validation loss\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {loss.item()}, Test Loss: {val_loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss   - Static Baseline: 13.9304, Linear Baseline: 22.1829\n",
      "Validation Loss - Static Baseline: 11.4824, Linear Baseline: 20.2710\n"
     ]
    }
   ],
   "source": [
    "# Calculate static and linear baselines (formula on ANS)\n",
    "# THIS IS CORRECT! DO NOT CHANGE!\n",
    "\n",
    "def static_baseline(X):\n",
    "    return X[:, 1:3]  # initial x,y coordinates\n",
    "\n",
    "def linear_baseline(X):\n",
    "    return X[:, 1:3] + X[:, 3:5] * 5  # initial x,y coordinates plus velocity times time\n",
    "\n",
    "def compute_baseline_loss(baseline_fn, dataloader):\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        predictions = baseline_fn(batch.x).to(device)\n",
    "        total_loss += criterion(predictions, batch.y).item() * batch.num_graphs\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "train_loss_static = compute_baseline_loss(static_baseline, dataloader)\n",
    "train_loss_linear = compute_baseline_loss(linear_baseline, dataloader)\n",
    "\n",
    "val_loss_static = compute_baseline_loss(static_baseline, val_dataloader)\n",
    "val_loss_linear = compute_baseline_loss(linear_baseline, val_dataloader)\n",
    "\n",
    " # now print out with filler spaces to make it easier to read\n",
    "print(f'Training Loss   - Static Baseline: {train_loss_static:0.4f}, Linear Baseline: {train_loss_linear:0.4f}')\n",
    "print(f'Validation Loss - Static Baseline: {val_loss_static:0.4f}, Linear Baseline: {val_loss_linear:0.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 5), (8, 49, 4))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check datashape\n",
    "X, y= load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Zoo for TASK 2\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn as nn\n",
    "\n",
    "class GraphLSTM(torch.nn.Module):\n",
    "    # Test MSE: 1.75 Train MSE: 0.40 (100 epochs)\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, num_time_steps):\n",
    "        super(GraphLSTM, self).__init__()\n",
    "        self.conv1 = SAGEConv(num_features, hidden_channels*2)\n",
    "        self.conv2 = SAGEConv(hidden_channels*2, hidden_channels)\n",
    "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_channels, hidden_size=hidden_channels*2, batch_first=True)\n",
    "\n",
    "        # add a sequential 2 fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_channels*2, num_classes)\n",
    "        )\n",
    "        self.num_time_steps = num_time_steps\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # 1st GraphSAGE layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # 2nd GraphSAGE layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # 3rd GraphSAGE layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        # LSTM layer\n",
    "        # Repeat x along a new temporal dimension to create a sequence, with the repeated\n",
    "        # x as the input at each time step. This is necessary because the LSTM expects\n",
    "        # input of the form (batch_size, sequence_length, input_size).\n",
    "        x = x.unsqueeze(1).repeat(1, self.num_time_steps, 1)\n",
    "\n",
    "        # Pass the sequence of node states through the LSTM.\n",
    "        # Note that we discard the LSTM's hidden state output, as we are only\n",
    "        # interested in its output sequences for this application.\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        #  Pass it through the fully connected layers\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 49, 4])\n",
      "MSE Loss: 115.92279052734375\n"
     ]
    }
   ],
   "source": [
    "# Doing a single forward pass, checking the output shape and MSE\n",
    "model = GraphLSTM(num_features=5, hidden_channels=32, num_classes=4, num_time_steps=49).to(device)\n",
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "# Assume that the load_array function and create_adjacency_matrix function are defined somewhere above.\n",
    "X, y = load_array('data/task 2_3/train/trajectory_0.npz', task='task 2')\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "adjacency_matrix = create_adjacency_matrix(X, inverse_distance)\n",
    "edge_index = adjacency_matrix.nonzero().t()\n",
    "\n",
    "# Put these into a PyTorch Geometric Data object\n",
    "data = Data(x=X, y=y, edge_index=edge_index)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = data.to(device)\n",
    "\n",
    "# Forward pass\n",
    "out = model(data)\n",
    "print(f\"Output shape: {out.shape}\")\n",
    "\n",
    "# Calculate MSE loss\n",
    "loss = mse_loss(out, data.y)\n",
    "print(f\"MSE Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# DataLoaders for task 2\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, filenames, transform=None, pre_transform=None):\n",
    "        self.filenames = filenames\n",
    "        super(MyDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return self.filenames\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def get(self, idx):\n",
    "        X, y = load_array(self.filenames[idx], task='task 2')\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)   # y is now a 3D tensor\n",
    "\n",
    "        adjacency_matrix = create_adjacency_matrix(X, inverse_distance)\n",
    "        edge_index = adjacency_matrix.nonzero().t()\n",
    "\n",
    "        data = Data(x=X, y=y, edge_index=edge_index)  # y is now a 3D tensor\n",
    "\n",
    "        return data\n",
    "\n",
    "filenames = [f'data/task 2_3/train/trajectory_{i}.npz' for i in range(900)]\n",
    "dataset = MyDataset(root='data/task 2_3/train', filenames=filenames)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# Prepare for validation data set\n",
    "\n",
    "val_filenames = [f'data/task 2_3/test/trajectory_{i}.npz' for i in range(901, 1000)]\n",
    "val_dataset = MyDataset(root='data/task 2_3/test', filenames=val_filenames)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss   - Static Baseline: 5.0640, Linear Baseline: 6.2776\n",
      "Validation Loss - Static Baseline: 5.1950, Linear Baseline: 6.5654\n"
     ]
    }
   ],
   "source": [
    "# Calculate baseline losses\n",
    "\n",
    "def static_baseline(X):\n",
    "    initial_position = X[:, 1:3]  # initial x,y coordinates\n",
    "    # Repeat the initial position for each timestep\n",
    "    return initial_position.unsqueeze(1).repeat(1, 49, 1)  # assuming 49 timesteps\n",
    "\n",
    "def linear_baseline(X):\n",
    "    initial_position = X[:, 1:3]  # initial x,y coordinates\n",
    "    initial_velocity = X[:, 3:5]  # initial velocity\n",
    "    # Predict position for each timestep using v = u + at\n",
    "    return initial_position.unsqueeze(1) + initial_velocity.unsqueeze(1) * (torch.arange(49).to(X.device).reshape(1, -1, 1) / 10)  \n",
    "\n",
    "def compute_baseline_loss(baseline_fn, dataloader):\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        predictions = baseline_fn(batch.x).to(device)\n",
    "        # Only take the position labels for loss calculation\n",
    "        pos_labels = batch.y[..., :2]\n",
    "        total_loss += criterion(predictions, pos_labels).item() * batch.num_graphs\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "train_loss_static = compute_baseline_loss(static_baseline, dataloader)\n",
    "train_loss_linear = compute_baseline_loss(linear_baseline, dataloader)\n",
    "\n",
    "val_loss_static = compute_baseline_loss(static_baseline, val_dataloader)\n",
    "val_loss_linear = compute_baseline_loss(linear_baseline, val_dataloader)\n",
    "\n",
    " # now print out with filler spaces to make it easier to read\n",
    "print(f'Training Loss   - Static Baseline: {train_loss_static:0.4f}, Linear Baseline: {train_loss_linear:0.4f}')\n",
    "print(f'Validation Loss - Static Baseline: {val_loss_static:0.4f}, Linear Baseline: {val_loss_linear:0.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 4.492421627044678, Test Loss: 3.8196070940807614\n",
      "Epoch: 2, Training Loss: 3.257450819015503, Test Loss: 3.6452667592751857\n",
      "Epoch: 3, Training Loss: 3.0610716342926025, Test Loss: 3.63254846707739\n",
      "Epoch: 4, Training Loss: 3.3574633598327637, Test Loss: 3.292944002633143\n",
      "Epoch: 5, Training Loss: 3.316744327545166, Test Loss: 3.3803355139915388\n",
      "Epoch: 6, Training Loss: 3.196038246154785, Test Loss: 3.4154045076081245\n",
      "Epoch: 7, Training Loss: 2.9708309173583984, Test Loss: 3.1696535120106706\n",
      "Epoch: 8, Training Loss: 2.7852301597595215, Test Loss: 3.2285630871551207\n",
      "Epoch: 9, Training Loss: 2.843844175338745, Test Loss: 3.028306407157821\n",
      "Epoch: 10, Training Loss: 3.0775246620178223, Test Loss: 3.205664292730466\n",
      "Epoch: 11, Training Loss: 2.7328574657440186, Test Loss: 2.9798850218454995\n",
      "Epoch: 12, Training Loss: 2.7528631687164307, Test Loss: 2.9877344670921864\n",
      "Epoch: 13, Training Loss: 2.5883867740631104, Test Loss: 2.9970612261030407\n",
      "Epoch: 14, Training Loss: 2.657634973526001, Test Loss: 2.8338876468966707\n",
      "Epoch: 15, Training Loss: 2.4382879734039307, Test Loss: 2.7206908572803843\n",
      "Epoch: 16, Training Loss: 2.2607574462890625, Test Loss: 2.662496116426256\n",
      "Epoch: 17, Training Loss: 2.213453531265259, Test Loss: 2.614255512603606\n",
      "Epoch: 18, Training Loss: 2.6045937538146973, Test Loss: 2.6128789728338067\n",
      "Epoch: 19, Training Loss: 2.163558006286621, Test Loss: 2.466504186090797\n",
      "Epoch: 20, Training Loss: 2.0078516006469727, Test Loss: 2.411257464476306\n",
      "Epoch: 21, Training Loss: 1.9539929628372192, Test Loss: 2.3615808535103846\n",
      "Epoch: 22, Training Loss: 1.8806015253067017, Test Loss: 2.341483718217021\n",
      "Epoch: 23, Training Loss: 1.883000135421753, Test Loss: 2.308224482969804\n",
      "Epoch: 24, Training Loss: 1.8308777809143066, Test Loss: 2.2629710809148924\n",
      "Epoch: 25, Training Loss: 1.7931166887283325, Test Loss: 2.2334942552778454\n",
      "Epoch: 26, Training Loss: 1.769279956817627, Test Loss: 2.228972011142307\n",
      "Epoch: 27, Training Loss: 1.7185975313186646, Test Loss: 2.211316395287562\n",
      "Epoch: 28, Training Loss: 1.6565464735031128, Test Loss: 2.1620367825633346\n",
      "Epoch: 29, Training Loss: 1.644568681716919, Test Loss: 2.133935899445505\n",
      "Epoch: 30, Training Loss: 1.629380226135254, Test Loss: 2.133080826865302\n",
      "Epoch: 31, Training Loss: 1.595197319984436, Test Loss: 2.1128037722423825\n",
      "Epoch: 32, Training Loss: 1.5189690589904785, Test Loss: 2.073403264537002\n",
      "Epoch: 33, Training Loss: 1.478335976600647, Test Loss: 2.0577563300277246\n",
      "Epoch: 34, Training Loss: 1.5000803470611572, Test Loss: 2.0405314835635098\n",
      "Epoch: 35, Training Loss: 1.5188066959381104, Test Loss: 2.028951832742402\n",
      "Epoch: 36, Training Loss: 1.4050933122634888, Test Loss: 2.009977704346782\n",
      "Epoch: 37, Training Loss: 1.3897923231124878, Test Loss: 2.0126318353595156\n",
      "Epoch: 38, Training Loss: 1.3201714754104614, Test Loss: 1.997422786674114\n",
      "Epoch: 39, Training Loss: 1.308047890663147, Test Loss: 2.0076685192609074\n",
      "Epoch: 40, Training Loss: 1.2930155992507935, Test Loss: 1.9761526488294505\n",
      "Epoch: 41, Training Loss: 1.2587296962738037, Test Loss: 1.9799421074414494\n",
      "Epoch: 42, Training Loss: 1.2357022762298584, Test Loss: 1.9469501418296737\n",
      "Epoch: 43, Training Loss: 1.2178220748901367, Test Loss: 1.949245698524244\n",
      "Epoch: 44, Training Loss: 1.1945947408676147, Test Loss: 1.9447149989580867\n",
      "Epoch: 45, Training Loss: 1.1707215309143066, Test Loss: 1.9294171839049368\n",
      "Epoch: 46, Training Loss: 1.1683727502822876, Test Loss: 1.9081534062973176\n",
      "Epoch: 47, Training Loss: 1.17716383934021, Test Loss: 1.9300455637652465\n",
      "Epoch: 48, Training Loss: 1.2715392112731934, Test Loss: 1.9422078758779198\n",
      "Epoch: 49, Training Loss: 1.0912657976150513, Test Loss: 1.8663417088865029\n",
      "Epoch: 50, Training Loss: 1.0963177680969238, Test Loss: 1.8839983602966925\n",
      "Epoch: 51, Training Loss: 1.042839765548706, Test Loss: 1.9201331620264535\n",
      "Epoch: 52, Training Loss: 1.073016881942749, Test Loss: 1.8631505653111622\n",
      "Epoch: 53, Training Loss: 1.0211302042007446, Test Loss: 1.8567372211302169\n",
      "Epoch: 54, Training Loss: 1.0594862699508667, Test Loss: 1.8695497007081003\n",
      "Epoch: 55, Training Loss: 1.0726631879806519, Test Loss: 1.9382597557222\n",
      "Epoch: 56, Training Loss: 0.9944025874137878, Test Loss: 1.8912045160929363\n",
      "Epoch: 57, Training Loss: 0.9745213389396667, Test Loss: 1.86084466269522\n",
      "Epoch: 58, Training Loss: 0.9296538233757019, Test Loss: 1.82481791515543\n",
      "Epoch: 59, Training Loss: 0.9916203022003174, Test Loss: 1.8044501844078604\n",
      "Epoch: 60, Training Loss: 0.9617412090301514, Test Loss: 1.870365398098724\n",
      "Epoch: 61, Training Loss: 0.9996683597564697, Test Loss: 1.8482799867186883\n",
      "Epoch: 62, Training Loss: 0.8973446488380432, Test Loss: 1.7681787254834416\n",
      "Epoch: 63, Training Loss: 0.8338487148284912, Test Loss: 1.8163551694214946\n",
      "Epoch: 64, Training Loss: 0.8782777190208435, Test Loss: 1.8569168382220798\n",
      "Epoch: 65, Training Loss: 0.7941857576370239, Test Loss: 1.9297751368898335\n",
      "Epoch: 66, Training Loss: 0.871275782585144, Test Loss: 1.7592720166601317\n",
      "Epoch: 67, Training Loss: 0.7699201703071594, Test Loss: 1.7712838131972033\n",
      "Epoch: 68, Training Loss: 0.78212970495224, Test Loss: 1.7735705098720511\n",
      "Epoch: 69, Training Loss: 0.8173906803131104, Test Loss: 1.9292330380642053\n",
      "Epoch: 70, Training Loss: 1.0024551153182983, Test Loss: 1.7986640279943293\n",
      "Epoch: 71, Training Loss: 0.7869877815246582, Test Loss: 1.7753620557110719\n",
      "Epoch: 72, Training Loss: 0.6640892028808594, Test Loss: 1.7602695684240321\n",
      "Epoch: 73, Training Loss: 0.6991738080978394, Test Loss: 1.7664958334932424\n",
      "Epoch: 74, Training Loss: 0.656101405620575, Test Loss: 1.7777931377141163\n",
      "Epoch: 75, Training Loss: 0.7444797158241272, Test Loss: 1.8338032190245812\n",
      "Epoch: 76, Training Loss: 0.8798477053642273, Test Loss: 1.7988200332179214\n",
      "Epoch: 77, Training Loss: 1.0963393449783325, Test Loss: 1.8303481051416108\n",
      "Epoch: 78, Training Loss: 0.796108603477478, Test Loss: 1.7052664359410603\n",
      "Epoch: 79, Training Loss: 0.6447919607162476, Test Loss: 1.760170169550963\n",
      "Epoch: 80, Training Loss: 0.580915093421936, Test Loss: 1.8437231791139854\n",
      "Epoch: 81, Training Loss: 0.5770276784896851, Test Loss: 1.7923567367322517\n",
      "Epoch: 82, Training Loss: 0.566769540309906, Test Loss: 1.8560392712101792\n",
      "Epoch: 83, Training Loss: 0.49613693356513977, Test Loss: 1.843334836189193\n",
      "Epoch: 84, Training Loss: 0.520095944404602, Test Loss: 1.7323930516387478\n",
      "Epoch: 85, Training Loss: 0.527063250541687, Test Loss: 1.697480442548039\n",
      "Epoch: 86, Training Loss: 0.6106692552566528, Test Loss: 1.7533043743384005\n",
      "Epoch: 87, Training Loss: 0.6425750851631165, Test Loss: 1.7202717884622438\n",
      "Epoch: 88, Training Loss: 0.9633708000183105, Test Loss: 1.8540702239431517\n",
      "Epoch: 89, Training Loss: 0.5675005912780762, Test Loss: 1.71398789112014\n",
      "Epoch: 90, Training Loss: 0.441649854183197, Test Loss: 1.67743841084567\n",
      "Epoch: 91, Training Loss: 0.4486118257045746, Test Loss: 1.6996283543230308\n",
      "Epoch: 92, Training Loss: 0.4225211441516876, Test Loss: 1.6762984003683534\n",
      "Epoch: 93, Training Loss: 0.37635132670402527, Test Loss: 1.6947272317578095\n",
      "Epoch: 94, Training Loss: 0.3560681939125061, Test Loss: 1.6774773453221177\n",
      "Epoch: 95, Training Loss: 0.3524099886417389, Test Loss: 1.6750462163578381\n",
      "Epoch: 96, Training Loss: 0.3214910626411438, Test Loss: 1.684324065844218\n",
      "Epoch: 97, Training Loss: 0.31219902634620667, Test Loss: 1.6966228364693998\n",
      "Epoch: 98, Training Loss: 0.3301684558391571, Test Loss: 1.7255979270646067\n",
      "Epoch: 99, Training Loss: 0.3553789556026459, Test Loss: 1.7351540375237513\n",
      "Epoch: 100, Training Loss: 0.41246840357780457, Test Loss: 1.7527181740963098\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "device = \"mps\" #NOTE: change to cuda or cpu if not apple silicon \n",
    "model = GraphLSTM(num_features=5, hidden_channels=32, num_classes=4, num_time_steps=49).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = torch.nn.MSELoss()  # we use Mean Squared Error loss for regression tasks\n",
    "\n",
    "for epoch in range(100):  # run for 100 epochs\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)  # move batch to the device\n",
    "        optimizer.zero_grad()  # set gradients to zero\n",
    "        out = model(batch)  # forward pass\n",
    "\n",
    "        # Only take the position predictions (first two dimensions of the last dimension) for loss calculation\n",
    "        pos_out = out[..., :2]\n",
    "        pos_labels = batch.y[..., :2]\n",
    "\n",
    "        loss = criterion(pos_out, pos_labels)  # compute loss\n",
    "        loss.backward()  # backward pass (compute gradients)\n",
    "        optimizer.step()  # update model parameters\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            pos_out = out[..., :2]\n",
    "            pos_labels = batch.y[..., :2]\n",
    "            val_loss += criterion(pos_out, pos_labels).item() * batch.num_graphs\n",
    "\n",
    "    val_loss /= len(val_dataset)  # compute average validation loss\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Training Loss: {loss.item()}, Test Loss: {val_loss}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "Plots, checking errors, tensors, anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/_gr926652s36cq6g6g4hfcdh0000gn/T/ipykernel_55628/3402136978.py:47: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  colors = plt.cm.get_cmap('rainbow', len(y))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Plot a single trajectory\n",
    "i = np.random.randint(low=0, high=899) # Index of trajectory\n",
    "X, y= load_array(f'data/task 2_3/train/trajectory_{i}.npz', task='task 2')\n",
    "# convert to tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Make predictions\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# WARNING! This redefines the create_adjacency_matrix function from earlier\n",
    "def create_adjacency_matrix(X):\n",
    "    # Calculate Euclidean distance\n",
    "    distances = pdist(X[:, 1:3], metric='euclidean')\n",
    "\n",
    "    # Convert pairwise distances into a square matrix.\n",
    "    adjacency_matrix = squareform(distances)\n",
    "\n",
    "    # Inverse the distances to get inverse distance adjacency\n",
    "    adjacency_matrix = 1 / (adjacency_matrix + 1e-5)  # add a small value to avoid division by zero\n",
    "\n",
    "    # Get edge index from adjacency matrix\n",
    "    edge_index = torch.tensor(np.where(adjacency_matrix != 0), dtype=torch.long)\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "edge_index = create_adjacency_matrix(X.numpy())\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Assuming X, y are the tensors to be plotted\n",
    "# Assuming edge_index is created\n",
    "\n",
    "data = Data(x=X, y=y, edge_index=edge_index)\n",
    "data = data.to(device)  # move data to the device where the model is\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Turn off gradients for prediction\n",
    "    prediction = model(data)  # Get prediction\n",
    "\n",
    "# Detach the prediction from the device and reshape to match y's shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_trajectory_with_baseline(X, y, plot_start=True):\n",
    "    colors = plt.cm.get_cmap('rainbow', len(y))\n",
    "\n",
    "    for idx, traj in enumerate(y):\n",
    "        color = colors(idx)\n",
    "\n",
    "        if plot_start:\n",
    "            plt.scatter(X[idx, 1], X[idx, 2], color=color, marker='o')  # plot start positions\n",
    "\n",
    "        plt.plot(traj[:, 0], traj[:, 1], color=color, linestyle='-', marker='o')  # plot real trajectory\n",
    "\n",
    "        # linear_baseline: initial x,y coordinates plus velocity times time\n",
    "        preds = np.zeros_like(traj)\n",
    "        for t in range(len(preds)):\n",
    "            preds[t, 0:2] = X[idx, 1:3] + X[idx, 3:5] * t\n",
    "\n",
    "        plt.plot(preds[:, 0], preds[:, 1], color=color, linestyle='--', marker='x', alpha=0.5)  # plot baseline predictions\n",
    "    # set title for plot\n",
    "    plt.title(f\"Trajectory with Baseline Predictions for trajectory {i}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_trajectory_with_baseline(X.numpy(), y.numpy())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
